{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.82 üöÄ Python-3.9.19 torch-2.4.0+cu121 CPU (Intel Core(TM) i9-14900K)\n",
      "YOLOv9t summary (fused): 486 layers, 2,094,000 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov9t.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (4.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.32...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 0.9s, saved as 'yolov9t.onnx' (8.4 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.20.0...\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725116864.018555 1386380 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1725116864.426461 1386380 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1725116864.426486 1386380 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1725116864.840594 1386380 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "W0000 00:00:1725116865.201019 1386380 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1725116865.201038 1386380 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n",
      "\u001b[34mInput signature information for quantization\u001b[0m\n",
      "\u001b[34msignature_name\u001b[0m: serving_default\n",
      "\u001b[34minput_name.0\u001b[0m: images \u001b[34mshape\u001b[0m: (1, 640, 640, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725116867.207532 1386380 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1725116867.207547 1386380 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDynamic Range Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725116868.013577 1386380 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1725116868.013598 1386380 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINT8 Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725116881.723850 1386380 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1725116881.723866 1386380 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFull INT8 Quantization tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725116895.122964 1386380 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1725116895.122979 1386380 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINT8 Quantization with int16 activations tflite output complete!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1725116921.221767 1386380 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1725116921.221782 1386380 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mFull INT8 Quantization with int16 activations tflite output complete!\u001b[0m\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 97.9s, saved as 'yolov9t_saved_model' (29.1 MB)\n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m WARNING ‚ö†Ô∏è Edge TPU known bug https://github.com/ultralytics/ultralytics/issues/1185\n",
      "\n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m starting export with Edge TPU compiler 16.0.384591198...\n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m running 'edgetpu_compiler -s -d -k 10 --out_dir \"yolov9t_saved_model\" \"yolov9t_saved_model/yolov9t_full_integer_quant.tflite\"'\n",
      "Edge TPU Compiler version 16.0.384591198\n",
      "Searching for valid delegate with step 10\n",
      "Try to compile segment with 676 ops\n",
      "Started a compilation timeout timer of 180 seconds.\n",
      "\n",
      "Model compiled successfully in 3455 ms.\n",
      "\n",
      "Input model: yolov9t_saved_model/yolov9t_full_integer_quant.tflite\n",
      "Input size: 2.24MiB\n",
      "Output model: yolov9t_saved_model/yolov9t_full_integer_quant_edgetpu.tflite\n",
      "Output size: 3.37MiB\n",
      "On-chip memory used for caching model parameters: 3.16MiB\n",
      "On-chip memory remaining for caching model parameters: 3.42MiB\n",
      "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
      "Number of Edge TPU subgraphs: 1\n",
      "Total number of operations: 676\n",
      "Operation log: yolov9t_saved_model/yolov9t_full_integer_quant_edgetpu.log\n",
      "\n",
      "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
      "Number of operations that will run on Edge TPU: 652\n",
      "Number of operations that will run on CPU: 24\n",
      "\n",
      "Operator                       Count      Status\n",
      "\n",
      "PAD                            7          Mapped to Edge TPU\n",
      "AVERAGE_POOL_2D                5          Mapped to Edge TPU\n",
      "SUB                            2          More than one subgraph is not supported\n",
      "QUANTIZE                       1          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "QUANTIZE                       2          Mapped to Edge TPU\n",
      "LOGISTIC                       1          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "LOGISTIC                       179        Mapped to Edge TPU\n",
      "MAX_POOL_2D                    3          Mapped to Edge TPU\n",
      "TRANSPOSE                      3          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "TRANSPOSE                      1          Mapped to Edge TPU\n",
      "STRIDED_SLICE                  16         Mapped to Edge TPU\n",
      "STRIDED_SLICE                  2          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "STRIDED_SLICE                  2          More than one subgraph is not supported\n",
      "CONCATENATION                  30         Mapped to Edge TPU\n",
      "CONCATENATION                  2          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "RESIZE_NEAREST_NEIGHBOR        2          Mapped to Edge TPU\n",
      "CONV_2D                        185        Mapped to Edge TPU\n",
      "CONV_2D                        1          More than one subgraph is not supported\n",
      "MUL                            179        Mapped to Edge TPU\n",
      "MUL                            2          More than one subgraph is not supported\n",
      "ADD                            2          More than one subgraph is not supported\n",
      "ADD                            42         Mapped to Edge TPU\n",
      "RESHAPE                        3          Operation is otherwise supported, but not mapped due to some unspecified limitation\n",
      "RESHAPE                        1          Mapped to Edge TPU\n",
      "RESHAPE                        2          More than one subgraph is not supported\n",
      "SOFTMAX                        1          More than one subgraph is not supported\n",
      "Compilation child process completed within timeout period.\n",
      "Compilation succeeded! \n",
      "\u001b[34m\u001b[1mEdge TPU:\u001b[0m export success ‚úÖ 3.7s, saved as 'yolov9t_saved_model/yolov9t_full_integer_quant_edgetpu.tflite' (3.4 MB)\n",
      "\n",
      "Export complete (103.0s)\n",
      "Results saved to \u001b[1m/home/hanyong/yolov9\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov9t_saved_model/yolov9t_full_integer_quant_edgetpu.tflite imgsz=640 int8 \n",
      "Validate:        yolo val task=detect model=yolov9t_saved_model/yolov9t_full_integer_quant_edgetpu.tflite imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Format                  | `format=argument`         | Model\n",
    "# ---                     | ---                       | ---\n",
    "# PyTorch                 | -                         | yolov8n.pt\n",
    "# TorchScript             | `torchscript`             | yolov8n.torchscript\n",
    "# ONNX                    | `onnx`                    | yolov8n.onnx\n",
    "# OpenVINO                | `openvino`                | yolov8n_openvino_model/\n",
    "# TensorRT                | `engine`                  | yolov8n.engine\n",
    "# CoreML                  | `coreml`                  | yolov8n.mlpackage\n",
    "# TensorFlow SavedModel   | `saved_model`             | yolov8n_saved_model/\n",
    "# TensorFlow GraphDef     | `pb`                      | yolov8n.pb\n",
    "# TensorFlow Lite         | `tflite`                  | yolov8n.tflite\n",
    "# TensorFlow Edge TPU     | `edgetpu`                 | yolov8n_edgetpu.tflite\n",
    "# TensorFlow.js           | `tfjs`                    | yolov8n_web_model/\n",
    "# PaddlePaddle            | `paddle`                  | yolov8n_paddle_model/\n",
    "# NCNN                    | `ncnn`                    | yolov8n_ncnn_model/\n",
    "\n",
    "# More information\n",
    "# https://docs.ultralytics.com/modes/export/#arguments\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov9t.pt\")\n",
    "\n",
    "path = model.export(format=\"edgetpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
